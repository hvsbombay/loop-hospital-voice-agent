<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Loop AI - Hospital Network Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            padding: 60px 40px;
            max-width: 600px;
            width: 100%;
            text-align: center;
        }
        h1 {
            color: #333;
            margin-bottom: 10px;
            font-size: 2.5em;
        }
        .subtitle {
            color: #666;
            margin-bottom: 50px;
            font-size: 1.1em;
        }
        .microphone-btn {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 60px;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 0 auto 40px;
            display: flex;
            justify-content: center;
            align-items: center;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
        }
        .microphone-btn:hover {
            transform: scale(1.1);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.6);
        }
        .microphone-btn:active {
            transform: scale(0.95);
        }
        .microphone-btn.recording {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { box-shadow: 0 10px 30px rgba(245, 87, 108, 0.4); }
            50% { box-shadow: 0 10px 50px rgba(245, 87, 108, 0.8); }
            100% { box-shadow: 0 10px 30px rgba(245, 87, 108, 0.4); }
        }
        .label {
            color: #666;
            font-size: 1.1em;
            margin-top: 20px;
        }
        #output {
            margin-top: 40px;
            padding: 20px;
            background: #f5f5f5;
            border-radius: 10px;
            text-align: left;
            min-height: 100px;
            color: #333;
            display: none;
        }
        #output.active {
            display: block;
        }
        .info-banner {
            background: #e3f2fd;
            border-left: 4px solid #2196F3;
            padding: 12px;
            margin-bottom: 20px;
            border-radius: 4px;
            color: #1565c0;
            font-size: 0.95em;
        }
        .error-banner {
            background: #ffebee;
            border-left: 4px solid #f44336;
            padding: 12px;
            margin-bottom: 20px;
            border-radius: 4px;
            color: #c62828;
            font-size: 0.95em;
        }
        .success-banner {
            background: #e8f5e9;
            border-left: 4px solid #4caf50;
            padding: 12px;
            margin-bottom: 20px;
            border-radius: 4px;
            color: #2e7d32;
            font-size: 0.95em;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üè• Loop AI</h1>
        <p class="subtitle">Hospital Network Assistant</p>
        
        <div id="statusBanner" class="info-banner" style="display:none;"></div>
        
        <button class="microphone-btn" id="recordBtn" title="Note: Microphone requires HTTPS or localhost">üé§</button>
        <p class="label">Start Conversation (or use text below)</p>
        <div style="margin-top:20px; display:flex; gap:8px; justify-content:center;">
            <input id="textQuery" type="text" placeholder="Type your question (e.g. Tell me 3 hospitals around Bangalore)" style="flex:1; padding:10px; border-radius:8px; border:1px solid #ddd;" />
            <button id="sendText" style="padding:10px 16px; border-radius:8px; border:none; background:#667eea; color:white; cursor:pointer; font-weight:bold;">Send</button>
        </div>
        <div id="output">
            <strong>ü§ñ Loop AI Response:</strong>
            <p id="responseText"></p>
        </div>
    </div>

    <script>
        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];
        let recognition;
        let speechSynthesis = window.speechSynthesis;
        const recordBtn = document.getElementById('recordBtn');
        const output = document.getElementById('output');
        const responseText = document.getElementById('responseText');
        const statusBanner = document.getElementById('statusBanner');

        // Initialize Speech Recognition
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
        }

        // Check microphone support on page load
        window.addEventListener('load', () => {
            checkMicrophoneSupport();
        });

        async function checkMicrophoneSupport() {
            const hasGetUserMedia = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
            const hasSpeechRecognition = !!recognition;
            const hasSpeechSynthesis = !!speechSynthesis;
            const isSecureContext = window.isSecureContext || location.hostname === 'localhost' || location.hostname === '127.0.0.1';
            
            if (!hasGetUserMedia) {
                showStatus('‚ùå Microphone API not supported in your browser', 'error');
                recordBtn.disabled = true;
            } else if (!isSecureContext) {
                showStatus('‚ö†Ô∏è Microphone requires HTTPS. Using text-based queries instead.', 'error');
                recordBtn.disabled = true;
            } else if (!hasSpeechRecognition) {
                showStatus('‚ö†Ô∏è Speech recognition not supported. Using text-based queries instead.', 'error');
                recordBtn.disabled = true;
            } else {
                const features = [];
                if (hasSpeechRecognition) features.push('üé§ Voice Input');
                if (hasSpeechSynthesis) features.push('üîä Voice Output');
                showStatus(`‚úÖ Ready! ${features.join(' & ')} enabled. Click microphone to start.`, 'success');
                
                // Try to check permissions status
                try {
                    const permission = await navigator.permissions.query({ name: 'microphone' });
                    if (permission.state === 'granted') {
                        showStatus(`‚úÖ Voice chat ready! ${features.join(' & ')} available.`, 'success');
                    } else if (permission.state === 'denied') {
                        showStatus('‚ùå Microphone access denied. Please enable it in browser settings or use text queries', 'error');
                    }
                } catch (e) {
                    // Permissions API not fully supported, that's okay
                    console.log('Permissions API check failed:', e);
                }
            }
        }

        function speakText(text) {
            // Stop any ongoing speech
            if (speechSynthesis.speaking) {
                speechSynthesis.cancel();
            }
            
            if (!speechSynthesis) {
                console.error('Speech synthesis not supported');
                return;
            }

            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'en-US';
            utterance.rate = 1.0;
            utterance.pitch = 1.0;
            utterance.volume = 1.0;
            
            utterance.onstart = () => {
                showStatus('üîä Speaking...', 'info');
            };
            
            utterance.onend = () => {
                showStatus('‚úÖ Voice response complete. Click microphone to ask another question.', 'success');
            };
            
            utterance.onerror = (event) => {
                console.error('Speech synthesis error:', event);
                showStatus('‚ö†Ô∏è Voice output error. Response shown as text.', 'error');
            };
            
            speechSynthesis.speak(utterance);
        }

        function showStatus(message, type) {
            statusBanner.textContent = message;
            statusBanner.className = type === 'error' ? 'error-banner' : type === 'success' ? 'success-banner' : 'info-banner';
            statusBanner.style.display = 'block';
        }

        recordBtn.addEventListener('click', async () => {
            if (!isRecording) {
                // Start voice recognition
                if (!recognition) {
                    showStatus('‚ùå Speech recognition not available in your browser', 'error');
                    return;
                }

                try {
                    // Stop any ongoing speech
                    if (speechSynthesis.speaking) {
                        speechSynthesis.cancel();
                    }

                    isRecording = true;
                    recordBtn.classList.add('recording');
                    showStatus('üé§ Listening... Speak your question now', 'success');
                    responseText.textContent = 'üéôÔ∏è Listening... Please speak clearly.';
                    output.classList.add('active');
                    
                    let finalTranscript = '';
                    let interimTranscript = '';
                    
                    recognition.onresult = (event) => {
                        interimTranscript = '';
                        
                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            const transcript = event.results[i][0].transcript;
                            if (event.results[i].isFinal) {
                                finalTranscript += transcript + ' ';
                            } else {
                                interimTranscript += transcript;
                            }
                        }
                        
                        // Show interim results
                        responseText.textContent = `üéôÔ∏è Hearing: "${interimTranscript || finalTranscript}"`;
                    };
                    
                    recognition.onend = async () => {
                        isRecording = false;
                        recordBtn.classList.remove('recording');
                        
                        if (finalTranscript.trim()) {
                            showStatus('‚è≥ Processing your question...', 'info');
                            responseText.textContent = `üìù You said: "${finalTranscript.trim()}"\n\nü§î Thinking...`;
                            
                            // Send to backend
                            await processVoiceQuery(finalTranscript.trim());
                        } else {
                            showStatus('‚ö†Ô∏è No speech detected. Try again.', 'error');
                            responseText.textContent = '‚ö†Ô∏è No speech detected. Please try again or use the text box.';
                        }
                    };
                    
                    recognition.onerror = (event) => {
                        console.error('Speech recognition error:', event.error);
                        isRecording = false;
                        recordBtn.classList.remove('recording');
                        
                        let errorMsg = '';
                        if (event.error === 'not-allowed' || event.error === 'permission-denied') {
                            errorMsg = '‚ùå Microphone permission denied. Please allow access and try again.';
                            showStatus('‚ùå Microphone access denied', 'error');
                        } else if (event.error === 'no-speech') {
                            errorMsg = '‚ö†Ô∏è No speech detected. Please try again.';
                            showStatus('‚ö†Ô∏è No speech detected', 'error');
                        } else if (event.error === 'network') {
                            errorMsg = '‚ùå Network error. Check your internet connection.';
                            showStatus('‚ùå Network error', 'error');
                        } else {
                            errorMsg = `‚ùå Speech recognition error: ${event.error}`;
                            showStatus(`‚ùå Error: ${event.error}`, 'error');
                        }
                        responseText.textContent = errorMsg;
                        output.classList.add('active');
                    };
                    
                    recognition.start();
                } catch (err) {
                    console.error('Recognition error:', err);
                    isRecording = false;
                    recordBtn.classList.remove('recording');
                    showStatus('‚ùå Failed to start voice recognition', 'error');
                    responseText.textContent = '‚ùå Voice recognition error. Please use the text box below.';
                    output.classList.add('active');
                }
            } else {
                // Stop recording
                if (recognition) {
                    recognition.stop();
                }
                isRecording = false;
                recordBtn.classList.remove('recording');
                showStatus('‚èπÔ∏è Processing...', 'info');
            }
        });

        async function processVoiceQuery(query) {
            try {
                const resp = await fetch('http://localhost:8000/converse', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: query })
                });
                
                if (!resp.ok) {
                    throw new Error('Backend error: ' + resp.status);
                }
                
                const data = await resp.json();
                const aiResponse = data.speech || JSON.stringify(data);
                
                // Display text response
                responseText.textContent = `üìù You: "${query}"\n\nü§ñ Loop AI: ${aiResponse}`;
                showStatus('üîä Speaking response...', 'success');
                
                // Speak the response
                speakText(aiResponse);
                
            } catch (e) {
                console.error('Error:', e);
                const errorMsg = '‚ùå Error: ' + e.message + '\n\nMake sure the backend server is running on http://localhost:8000';
                responseText.textContent = errorMsg;
                showStatus('‚ùå Failed to connect to backend', 'error');
                speakText('Sorry, I encountered an error connecting to the server. Please try again.');
            }
        }

        async function sendTextQuery() {
            const q = document.getElementById('textQuery').value.trim();
            if (!q) {
                showStatus('‚ö†Ô∏è Please enter a query', 'error');
                return;
            }
            
            // Stop any ongoing speech
            if (speechSynthesis.speaking) {
                speechSynthesis.cancel();
            }
            
            responseText.textContent = 'ü§î Thinking...';
            output.classList.add('active');
            showStatus('‚è≥ Processing query...', 'info');
            
            try {
                const resp = await fetch('http://localhost:8000/converse', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: q })
                });
                
                if (!resp.ok) {
                    throw new Error('Backend error: ' + resp.status);
                }
                
                const data = await resp.json();
                const aiResponse = data.speech || JSON.stringify(data);
                
                // Display text response
                responseText.textContent = `üìù You: "${q}"\n\nü§ñ Loop AI: ${aiResponse}`;
                showStatus('üîä Speaking response...', 'success');
                document.getElementById('textQuery').value = ''; // Clear input
                
                // Speak the response
                speakText(aiResponse);
                
            } catch (e) {
                console.error('Error:', e);
                responseText.textContent = '‚ùå Error: ' + e.message + '\n\nMake sure the backend server is running on http://localhost:8000';
                showStatus('‚ùå Failed to connect to backend', 'error');
            }
        }

        document.getElementById('sendText').addEventListener('click', sendTextQuery);
        
        // Allow Enter key to send query
        document.getElementById('textQuery').addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                sendTextQuery();
            }
        });
    </script>
</body>
</html>
